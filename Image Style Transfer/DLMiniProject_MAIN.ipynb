{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i43YA8yGXhDJ",
        "outputId": "4088174f-2946-4209-b744-59d876b32024"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/steubk/wikiart?dataset_version_number=1...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 31.4G/31.4G [05:48<00:00, 96.7MB/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data source import complete.\n"
          ]
        }
      ],
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "import kagglehub\n",
        "steubk_wikiart_path = kagglehub.dataset_download('steubk/wikiart')\n",
        "\n",
        "print('Data source import complete.')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-05-02T13:09:34.728515Z",
          "iopub.status.busy": "2025-05-02T13:09:34.727985Z",
          "iopub.status.idle": "2025-05-02T13:16:15.65396Z",
          "shell.execute_reply": "2025-05-02T13:16:15.652836Z",
          "shell.execute_reply.started": "2025-05-02T13:09:34.728487Z"
        },
        "id": "z78xXg8BXhDP",
        "outputId": "1cd6e971-aaf1-4007-9d41-a0ad64f77295",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m106.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m91.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m59.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m90.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n",
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "# Install required libraries in KaggleHub\n",
        "!pip install torch torchvision pandas matplotlib tqdm\n",
        "\n",
        "# Optional: Mount Google Drive for persistent storage (if linked with Colab)\n",
        "# Uncomment the following lines if you want to save artifacts to Google Drive\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "# Import necessary libraries\n",
        "import os\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import glob\n",
        "\n",
        "# Set device to GPU if available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'Using device: {device}')\n",
        "\n",
        "# Create directory for saving artifacts in KaggleHub\n",
        "artifacts_dir = '/kaggle/working/artifacts'\n",
        "os.makedirs(artifacts_dir, exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WFd8YTqGXhDQ"
      },
      "source": [
        "# **PRETRAITEMENT**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8j9yGSSbXhDR",
        "outputId": "a27851fa-d4c6-432d-942f-b0f587e2a9aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading dataset from /root/.cache/kagglehub/datasets/steubk/wikiart/versions/1\n",
            "Found 81444 images in /root/.cache/kagglehub/datasets/steubk/wikiart/versions/1\n",
            "Example image paths: ['/root/.cache/kagglehub/datasets/steubk/wikiart/versions/1/Abstract_Expressionism/aaron-siskind_acolman-1-1955.jpg', '/root/.cache/kagglehub/datasets/steubk/wikiart/versions/1/Abstract_Expressionism/aaron-siskind_chicago-1951.jpg', '/root/.cache/kagglehub/datasets/steubk/wikiart/versions/1/Abstract_Expressionism/aaron-siskind_chicago-6-1961.jpg']\n",
            "Dataset loaded successfully with 1000 images\n",
            "Fri May  2 17:48:30 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   39C    P8              9W /   70W |       2MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "# Configuration\n",
        "DATA_DIR = steubk_wikiart_path  \n",
        "IMAGE_SIZE = 512\n",
        "BATCH_SIZE = 8   \n",
        "MAX_SAMPLES = 1000  \n",
        "\n",
        "# normalize to [-1 , 1]\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
        "    transforms.ToTensor(),  # [0, 1]\n",
        "    transforms.Lambda(lambda x: x * 2 - 1)  # [-1, 1]\n",
        "])\n",
        "\n",
        "#customize DS\n",
        "class LimitedWikiArtDataset(Dataset):\n",
        "    def __init__(self, data_dir, max_samples=MAX_SAMPLES):\n",
        "        self.data_dir = data_dir\n",
        "        #ensure dirs exists\n",
        "        if not os.path.exists(data_dir):\n",
        "            raise ValueError(f'Dataset directory {data_dir} does not exist.')\n",
        "\n",
        "        self.image_paths = []\n",
        "        for ext in ['jpg', 'jpeg', 'png', 'JPG']:\n",
        "            self.image_paths.extend(glob.glob(os.path.join(data_dir, f'**/*.{ext}'), recursive=True))\n",
        "\n",
        "        \n",
        "        self.image_paths = sorted(list(set(self.image_paths)))\n",
        "\n",
        "        print(f'Found {len(self.image_paths)} images in {data_dir}')\n",
        "        if len(self.image_paths) > 0:\n",
        "            print(f'Example image paths: {self.image_paths[:3]}')\n",
        "\n",
        "        if not self.image_paths:\n",
        "            raise ValueError(f'No images found in {data_dir}. Ensure the dataset contains .jpg, .jpeg, or .png files.')\n",
        "\n",
        "        self.image_paths = self.image_paths[:min(max_samples, len(self.image_paths))]\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.image_paths[idx]\n",
        "        try:\n",
        "            img = Image.open(img_path).convert('RGB')\n",
        "            img = self.transform(img)\n",
        "            return {'image': img}\n",
        "        except Exception as e:\n",
        "            print(f'Error loading image {img_path}: {e}')\n",
        "            return {'image': torch.zeros(3, IMAGE_SIZE, IMAGE_SIZE)}\n",
        "\n",
        "#load sample DS\n",
        "try:\n",
        "    print('Loading dataset from', DATA_DIR)\n",
        "    dataset = LimitedWikiArtDataset(data_dir=DATA_DIR, max_samples=MAX_SAMPLES)\n",
        "    print(f'Dataset loaded successfully with {len(dataset)} images')\n",
        "except Exception as e:\n",
        "    print(f'Error loading dataset: {e}')\n",
        "    raise\n",
        "\n",
        "# create dataholder for DS\n",
        "def collate_fn(examples):\n",
        "    images = []\n",
        "    for example in examples:\n",
        "        img = example['image']\n",
        "        # Skip dummy images\n",
        "        if img.sum() == 0:\n",
        "            continue\n",
        "        images.append(img)\n",
        "    if not images:\n",
        "        raise ValueError('No valid images in batch')\n",
        "    return torch.stack(images)\n",
        "\n",
        "# Wrap dataset in a DataLoader for batching\n",
        "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, collate_fn=collate_fn, num_workers=0, shuffle=True)\n",
        "\n",
        "# Test loading a batch\n",
        "#print('Testing DataLoader...')\n",
        "#for i, batch in enumerate(tqdm(dataloader, desc='Testing DataLoader', total=10)):\n",
        "#    print(f'Batch {i+1} shape: {batch.shape}')  # Expected: (batch_size, 3, 128, 128)\n",
        "#    batch = batch.to(device)  # Move to GPU\n",
        "#    print(f'Batch moved to {device}')\n",
        "#    if i >= 9:  # Stop after 10 batches\n",
        "#        break\n",
        "\n",
        "# Check GPU memory usage\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ApfiLZCxXhDS",
        "outputId": "4ed8cd31-181a-4c35-f697-5f156ea088ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Style image tensor min: -0.9529411792755127, max: 0.8980392217636108\n"
          ]
        }
      ],
      "source": [
        "#load and preprocess style image\n",
        "#note: uload georges-seurat_sunday-afternoon-on-the-island-of-la-grande-jatte.jpg to /kaggle/input/georges-seurat_sunday-afternoon-on-the-island-of-la-grande-jatte/ or /kaggle/working/\n",
        "style_img_path = './style-image.jpg'\n",
        "if not os.path.exists(style_img_path):\n",
        "    style_img_path = '/kaggle/working/air-terjun.jpg'\n",
        "    if not os.path.exists(style_img_path):\n",
        "        print('Style image not found. Please upload georges-seurat_sunday-afternoon-on-the-island-of-la-grande-jatte.jpg to KaggleHub.')\n",
        "        try:\n",
        "            from google.colab import files\n",
        "            uploaded = files.upload()\n",
        "            style_img_path = list(uploaded.keys())[0]  # Use uploaded file\n",
        "        except ImportError:\n",
        "            print('Colab file upload not available in KaggleHub. Please upload georges-seurat_sunday-afternoon-on-the-island-of-la-grande-jatte.jpg manually to /kaggle/working/')\n",
        "            raise FileNotFoundError('Style image not found')\n",
        "\n",
        "try:\n",
        "    style_img = Image.open(style_img_path).convert('RGB')\n",
        "    style_tensor = transform(style_img).unsqueeze(0).to(device)\n",
        "    print(f'Style image tensor min: {style_tensor.min()}, max: {style_tensor.max()}')  # Should be [-1, 1]\n",
        "except Exception as e:\n",
        "    print(f'Error loading style image: {e}')\n",
        "    raise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cb1S97dcXhDT"
      },
      "outputs": [],
      "source": [
        "# transformer-NETWORK\n",
        "class ConvLayer(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, stride):\n",
        "        super(ConvLayer, self).__init__()\n",
        "        reflection_padding = kernel_size // 2\n",
        "        self.layer = nn.Sequential(\n",
        "            nn.ReflectionPad2d(reflection_padding),\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size, stride),\n",
        "            nn.InstanceNorm2d(out_channels, affine=True),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layer(x)\n",
        "\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, channels):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "        self.block = nn.Sequential(\n",
        "            ConvLayer(channels, channels, 3, 1),\n",
        "            ConvLayer(channels, channels, 3, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.block(x)\n",
        "\n",
        "class TransformerNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(TransformerNet, self).__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            ConvLayer(3, 32, 9, 1),\n",
        "            ConvLayer(32, 64, 3, 2),\n",
        "            ConvLayer(64, 128, 3, 2),\n",
        "        )\n",
        "        self.residuals = nn.Sequential(\n",
        "            ResidualBlock(128),\n",
        "            ResidualBlock(128),\n",
        "            ResidualBlock(128),\n",
        "            ResidualBlock(128),\n",
        "            ResidualBlock(128),\n",
        "        )\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Upsample(scale_factor=2),\n",
        "            ConvLayer(128, 64, 3, 1),\n",
        "            nn.Upsample(scale_factor=2),\n",
        "            ConvLayer(64, 32, 3, 1),\n",
        "            ConvLayer(32, 3, 9, 1),\n",
        "            nn.Tanh(),  # [-1, 1] output\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        x = self.residuals(x)\n",
        "        x = self.decoder(x)\n",
        "        return x\n",
        "\n",
        "# Instantiate and move to device\n",
        "transformer = TransformerNet().to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cs7Og5D_XhDU"
      },
      "source": [
        "# **2 : Définir la perte (Loss)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NIdgyYjXXhDV",
        "outputId": "abcaeb98-6008-4596-d7b0-ec741e848b19"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg19-dcbb9e9d.pth\" to /root/.cache/torch/hub/checkpoints/vgg19-dcbb9e9d.pth\n",
            "100%|██████████| 548M/548M [00:07<00:00, 76.9MB/s]\n"
          ]
        }
      ],
      "source": [
        "# VGG features for content and style loss\n",
        "class VGGFeatures(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(VGGFeatures, self).__init__()\n",
        "        vgg = models.vgg19(weights=models.VGG19_Weights.DEFAULT).features\n",
        "        self.relu1_2 = nn.Sequential(*vgg[:4])\n",
        "        self.relu2_2 = nn.Sequential(*vgg[4:9])\n",
        "        self.relu3_3 = nn.Sequential(*vgg[9:16])\n",
        "        self.relu4_3 = nn.Sequential(*vgg[16:23])\n",
        "        for param in self.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = {}\n",
        "        out['relu1_2'] = self.relu1_2(x)\n",
        "        out['relu2_2'] = self.relu2_2(out['relu1_2'])\n",
        "        out['relu3_3'] = self.relu3_3(out['relu2_2'])\n",
        "        out['relu4_3'] = self.relu4_3(out['relu3_3'])\n",
        "        return out\n",
        "\n",
        "# move VGG isntance todevice\n",
        "vgg = VGGFeatures().to(device).eval()\n",
        "\n",
        "#gram_matrix for style loss\n",
        "def gram_matrix(tensor):\n",
        "    b, c, h, w = tensor.size()\n",
        "    features = tensor.view(b, c, h * w)\n",
        "    G = torch.bmm(features, features.transpose(1, 2))\n",
        "    return G / (c * h * w)\n",
        "\n",
        "#compute content loss / style loss\n",
        "def compute_losses(content_img, style_img, stylized_img, vgg):\n",
        "    content_features = vgg(content_img)\n",
        "    style_features = vgg(style_img)\n",
        "    stylized_features = vgg(stylized_img)\n",
        "\n",
        "    # content_loss (using relu4_3)\n",
        "    content_loss = F.mse_loss(stylized_features['relu4_3'], content_features['relu4_3'])\n",
        "\n",
        "    # style_loss (using multiple layers)\n",
        "    style_loss = 0\n",
        "    style_layers = ['relu1_2', 'relu2_2', 'relu3_3', 'relu4_3']\n",
        "    for layer in style_layers:\n",
        "        stylized_gram = gram_matrix(stylized_features[layer])\n",
        "        style_gram = gram_matrix(style_features[layer])\n",
        "        style_loss += F.mse_loss(stylized_gram, style_gram)\n",
        "\n",
        "    return content_loss, style_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GEaiHVkAXhDW"
      },
      "source": [
        "# **3 : Boucle d'entraînement**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c_jNhjAWXhDW",
        "outputId": "7171d9b7-8f27-4ff4-e5ed-d511d2139ed2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ℹ️ No checkpoint found, training from scratch\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/50:   0%|          | 0/125 [00:00<?, ?it/s]<ipython-input-7-4b8ebde704d1>:46: UserWarning: Using a target size (torch.Size([1, 64, 64])) that is different to the input size (torch.Size([8, 64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  style_loss += F.mse_loss(stylized_gram, style_gram)\n",
            "<ipython-input-7-4b8ebde704d1>:46: UserWarning: Using a target size (torch.Size([1, 128, 128])) that is different to the input size (torch.Size([8, 128, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  style_loss += F.mse_loss(stylized_gram, style_gram)\n",
            "<ipython-input-7-4b8ebde704d1>:46: UserWarning: Using a target size (torch.Size([1, 256, 256])) that is different to the input size (torch.Size([8, 256, 256])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  style_loss += F.mse_loss(stylized_gram, style_gram)\n",
            "<ipython-input-7-4b8ebde704d1>:46: UserWarning: Using a target size (torch.Size([1, 512, 512])) that is different to the input size (torch.Size([8, 512, 512])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  style_loss += F.mse_loss(stylized_gram, style_gram)\n",
            "Epoch 1/50: 100%|██████████| 125/125 [04:36<00:00,  2.21s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, Content Loss: 3.8468, Style Loss: 0.0000, Total Loss: 638019.8692\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2/50: 100%|██████████| 125/125 [04:38<00:00,  2.23s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2, Content Loss: 3.1908, Style Loss: 0.0000, Total Loss: 438264.0557\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3/50: 100%|██████████| 125/125 [04:39<00:00,  2.23s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3, Content Loss: 2.9130, Style Loss: 0.0000, Total Loss: 394361.3285\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4/50: 100%|██████████| 125/125 [04:38<00:00,  2.23s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4, Content Loss: 2.6980, Style Loss: 0.0000, Total Loss: 363479.7100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5/50: 100%|██████████| 125/125 [04:38<00:00,  2.23s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5, Content Loss: 2.6991, Style Loss: 0.0000, Total Loss: 368758.4228\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 6/50: 100%|██████████| 125/125 [04:39<00:00,  2.24s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6, Content Loss: 2.5006, Style Loss: 0.0000, Total Loss: 340456.6252\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 7/50: 100%|██████████| 125/125 [04:38<00:00,  2.23s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7, Content Loss: 2.3831, Style Loss: 0.0000, Total Loss: 325098.7413\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 8/50: 100%|██████████| 125/125 [04:37<00:00,  2.22s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8, Content Loss: 2.2803, Style Loss: 0.0000, Total Loss: 313434.5109\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 9/50: 100%|██████████| 125/125 [04:33<00:00,  2.19s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9, Content Loss: 2.2219, Style Loss: 0.0000, Total Loss: 306339.9771\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 10/50: 100%|██████████| 125/125 [04:33<00:00,  2.19s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10, Content Loss: 2.1517, Style Loss: 0.0000, Total Loss: 298530.9477\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 11/50: 100%|██████████| 125/125 [04:33<00:00,  2.19s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 11, Content Loss: 2.0662, Style Loss: 0.0000, Total Loss: 288508.1506\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 12/50: 100%|██████████| 125/125 [04:39<00:00,  2.24s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 12, Content Loss: 2.0753, Style Loss: 0.0000, Total Loss: 290392.4671\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 13/50: 100%|██████████| 125/125 [04:38<00:00,  2.23s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 13, Content Loss: 2.0634, Style Loss: 0.0000, Total Loss: 288754.6302\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 14/50: 100%|██████████| 125/125 [04:38<00:00,  2.23s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 14, Content Loss: 1.9622, Style Loss: 0.0000, Total Loss: 277144.2679\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 15/50: 100%|██████████| 125/125 [04:38<00:00,  2.23s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 15, Content Loss: 1.9365, Style Loss: 0.0000, Total Loss: 274128.1550\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 16/50: 100%|██████████| 125/125 [04:39<00:00,  2.23s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 16, Content Loss: 1.9132, Style Loss: 0.0000, Total Loss: 271911.0236\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 17/50: 100%|██████████| 125/125 [04:38<00:00,  2.23s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 17, Content Loss: 1.8548, Style Loss: 0.0000, Total Loss: 264752.5995\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 18/50: 100%|██████████| 125/125 [04:39<00:00,  2.23s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 18, Content Loss: 1.9008, Style Loss: 0.0000, Total Loss: 270446.2793\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 19/50:  46%|████▋     | 58/125 [02:09<02:30,  2.25s/it]"
          ]
        }
      ],
      "source": [
        "# Checkpoint saving and loading\n",
        "def save_checkpoint(transformer, optimizer, epoch, path=os.path.join(artifacts_dir, 'checkpoint.pth')):\n",
        "    torch.save({\n",
        "        'epoch': epoch,\n",
        "        'model_state_dict': transformer.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict()\n",
        "    }, path)\n",
        "\n",
        "def load_checkpoint(transformer, optimizer, path=os.path.join(artifacts_dir, 'checkpoint.pth')):\n",
        "    if os.path.isfile(path):\n",
        "        checkpoint = torch.load(path, map_location=device)\n",
        "        transformer.load_state_dict(checkpoint['model_state_dict'])\n",
        "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "        start_epoch = checkpoint['epoch'] + 1\n",
        "        print(f'✅ Checkpoint loaded, resuming from epoch {start_epoch}')\n",
        "        return start_epoch\n",
        "    else:\n",
        "        print('ℹ️ No checkpoint found, training from scratch')\n",
        "        return 0\n",
        "\n",
        "#traning looop\n",
        "def train(transformer, dataloader, style_tensor, vgg, epochs=50, content_weight=1e5, style_weight=1e10):\n",
        "    optimizer = torch.optim.Adam(transformer.parameters(), lr=1e-3)\n",
        "    start_epoch = load_checkpoint(transformer, optimizer)\n",
        "\n",
        "    # Lists to store losses for plotting\n",
        "    content_losses = []\n",
        "    style_losses = []\n",
        "    total_losses = []\n",
        "\n",
        "    transformer.train()\n",
        "    for epoch in range(start_epoch, epochs):\n",
        "        epoch_content_loss = 0\n",
        "        epoch_style_loss = 0\n",
        "        epoch_total_loss = 0\n",
        "        batch_count = 0\n",
        "\n",
        "        total_batches = (MAX_SAMPLES + BATCH_SIZE - 1) // BATCH_SIZE\n",
        "\n",
        "        for i, batch in enumerate(tqdm(dataloader, desc=f'Epoch {epoch+1}/{epochs}', total=total_batches)):\n",
        "            try:\n",
        "                batch = batch.to(device)\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                stylized = transformer(batch)\n",
        "\n",
        "                content_loss, style_loss = compute_losses(batch, style_tensor, stylized, vgg)\n",
        "                total_loss = content_weight * content_loss + style_weight * style_loss\n",
        "                total_loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                epoch_content_loss += content_loss.item()\n",
        "                epoch_style_loss += style_loss.item()\n",
        "                epoch_total_loss += total_loss.item()\n",
        "                batch_count += 1\n",
        "\n",
        "                # Save sample stylized image every 50 iterations\n",
        "                if i % 50 == 0:\n",
        "                    with torch.no_grad():\n",
        "                        img = denormalize(stylized[0]).permute(1, 2, 0).cpu().numpy()\n",
        "                        plt.imsave(os.path.join(artifacts_dir, f'stylized_epoch{epoch}_iter{i}.png'), img)\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f'Error in training batch {i}: {e}')\n",
        "                continue\n",
        "\n",
        "        if batch_count > 0:\n",
        "            content_losses.append(epoch_content_loss / batch_count)\n",
        "            style_losses.append(epoch_style_loss / batch_count)\n",
        "            total_losses.append(epoch_total_loss / batch_count)\n",
        "\n",
        "            print(f'Epoch {epoch+1}, Content Loss: {content_losses[-1]:.4f}, Style Loss: {style_losses[-1]:.4f}, Total Loss: {total_losses[-1]:.4f}')\n",
        "\n",
        "        save_checkpoint(transformer, optimizer, epoch)\n",
        "\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.plot(content_losses, label='Content Loss')\n",
        "    plt.plot(style_losses, label='Style Loss')\n",
        "    plt.plot(total_losses, label='Total Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('Training Losses')\n",
        "    plt.legend()\n",
        "    plt.savefig(os.path.join(artifacts_dir, 'loss_plot.png'))\n",
        "    plt.close()\n",
        "\n",
        "    return content_losses, style_losses, total_losses\n",
        "\n",
        "def denormalize(img_tensor):\n",
        "    img = (img_tensor + 1) / 2  # Inverse of x*2 - 1\n",
        "    img = img.clamp(0, 1)\n",
        "    return img\n",
        "\n",
        "# Run training\n",
        "content_losses, style_losses, total_losses = train(transformer, dataloader, style_tensor, vgg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1s-OpDUXXhDX",
        "outputId": "c68edee3-7be6-49ce-fd75-6520a6b3fd20"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fri May  2 16:37:25 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   77C    P0             34W /   70W |    2018MiB /  15360MiB |      9%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "# Visualize sample images from the dataset\n",
        "dataiter = iter(dataloader)\n",
        "try:\n",
        "    images = next(dataiter)\n",
        "    fig, axes = plt.subplots(1, min(BATCH_SIZE, 4), figsize=(10, 3))\n",
        "    for idx in range(min(BATCH_SIZE, 4)):\n",
        "        img = denormalize(images[idx]).permute(1, 2, 0).cpu().numpy()\n",
        "        axes[idx].imshow(img)\n",
        "        axes[idx].axis('off')\n",
        "    plt.savefig(os.path.join(artifacts_dir, 'sample_images.png'))\n",
        "    plt.close()\n",
        "\n",
        "    # Visualize a stylized image\n",
        "    transformer.eval()\n",
        "    with torch.no_grad():\n",
        "        stylized = transformer(images[:1].to(device))\n",
        "        img = denormalize(stylized[0]).permute(1, 2, 0).cpu().numpy()\n",
        "        plt.imshow(img)\n",
        "        plt.axis('off')\n",
        "        plt.savefig(os.path.join(artifacts_dir, 'final_stylized.png'))\n",
        "        plt.close()\n",
        "except Exception as e:\n",
        "    print(f'Error visualizing images: {e}')\n",
        "\n",
        "# Save loss data to CSV for report\n",
        "loss_df = pd.DataFrame({\n",
        "    'Epoch': range(1, len(content_losses) + 1),\n",
        "    'Content Loss': content_losses,\n",
        "    'Style Loss': style_losses,\n",
        "    'Total Loss': total_losses\n",
        "})\n",
        "loss_df.to_csv(os.path.join(artifacts_dir, 'losses.csv'), index=False)\n",
        "\n",
        "# Check GPU memory usage after training\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "datasetId": 2477766,
          "sourceId": 4202543,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 31012,
      "isGpuEnabled": false,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
